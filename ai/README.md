# 인공지능 모델 설명

# 1. 챗봇 with Google Dialogflow

### 기능 개괄

---

- 박물관 전시회 정보를 사용자에게 안내하는 챗봇 모달

### 구현 방법

---

- google dialogflow api 활용
  - 챗봇 시나리오 작성 ([참조](https://www.notion.so/2c6c48e8bf744fb7ac8778e26b5f9830))
  - 상황별(인텐트) 예상 입력 데이터 생성 및 학습
  - 문의내용에서 검색에 필요한 키워드를 추출하는 커스텀 엔티티 생성

### 기능 목록

---

챗봇이 다음 질문이나 대화에 답변 가능

- 간단한 인사 `EX) 안녕하세요`
- 진행중인 전시회 일정 안내 `EX) 다음주에 열리는 전시회 알려줘`
- 구 별 박물관/미술관 안내 `EX) 종로구에 어떤 미술관 있어?`
- 특정기관 운영시간 안내 `EX) 국립중앙박물관 쉬는날이 언제야?`
- 특정기관 연락처 안내 `EX) 국립중앙박물관 전화번호가 뭐야?`
- 특정기관 입장료 안내 `EX) 국립중앙박물관 입장료가 얼마야?`
- 특정기관 위치 안내 `EX) 국립중앙박물관 어디에 있어?`
- 기타 문의 `EX) 국립중앙박물관에 장애인 전용 주차장 있어?`

### 페르소나

---

- 이름: 뮤즈
- 나이: 28
- 성격: 알잘딱깔쎈
- 특징: 아는 말만 알아들음

### 시나리오 및 감성분석 모델 워크플로우

---

AIbot은 아래 워크플로우에 따라 사용자의 질문을 분기하고 응답

[https://whimsical.com/exhibition-bot-UMPq8suUoRwm595MfNLh52](https://whimsical.com/exhibition-bot-UMPq8suUoRwm595MfNLh52)

# 2. 챗봇 리뷰 긍부정 분류기

## 1. 기능 소개

### 기능 개괄

---

- 사용자가 챗봇 사용 후 남긴 피드백의 긍부정을 판단

### 구현 방법

---

- BiLSTM 모델을 사용하여 약 50만개의 긍부정 라벨링이 된 데이터로 긍부정 판단 학습을 진행함

## 2. 기술 명세

### 2-1. 데이터셋

---

#### **세** **종류의** **데이터셋을** **사용한** **이유**

---

- 챗봇에 대한 리뷰만을 구성된 충분히 큰 크기의 데이터셋을 구할 수 없어서 긍부정 판단용으로 사용가능한 다른 최선의 데이터셋을 가져와서 사용함
- 학습에 사용된 데이터셋은 챗봇 리뷰를 분석하는 데에 특화되지 않았지만 각각 아래와 같은 효용이 있다고 판단하여 사용함
  - 네이버 영화리뷰의 경우 다양한 스토리, 컨텍스트에 대한 긍부정을 학습시키는데 유용
  - 네이버 쇼핑리뷰의 경우 특정 상품에 대한 문맥이 많이 섞여있지만 대체적으로 짧은 형태의 문장에 대한 긍부정을 학습시키는데 유용
  - 스팀 게임리뷰의 경우 게임 리뷰의 특성상 비속어, 은어와 관련된 긍부정을 학습시키는데 유용

위와 같은 이유로 세 종류의 데이터셋 모두를 활용하여 학습을 진행함

#### **네이버** **영화리뷰** **20만개** ([source](https://github.com/e9t/nsmc/))

---

- original source: [Naver Movie](https://movie.naver.com/movie/point/af/list.naver)
- 전체 글자 수가 140개 이하인 리뷰만 포함
- 긍정 부정의 비율이 1:1 으로 동일함
- 평점 1-4점짜리 리뷰는 부정(0)으로 라벨링
- 평점 9-10점짜리 리뷰는 긍정(1)으로 라벨링
- 평점 5-8점짜리 리뷰는 모두 제거

#### **네이버** **쇼핑리뷰** **약** **20만개** ([source](https://github.com/bab2min/corpus/tree/master/sentiment))

---

- original source: [Naver shopping](https://shopping.naver.com/)
- 평점 1, 2, 4, 5점짜리 리뷰만 포함
- 평점 1, 2점짜리 (부정) 샘플 수와 평점 4, 5점짜리 (긍정)으로 라벨링
- 샘플 수의 비율이 거의 1:1로 동일함

#### **스팀** **게임리뷰** **약** **10만개** ([source](https://github.com/bab2min/corpus/tree/master/sentiment))

---

- original source: [Steam](https://www.notion.so/https-news-kbs-co-kr-news-view-do-ncd-5577726-0340bb2c07cf4f4788b3e84e01d9a4d8)
- 게임 커뮤니티 특성상 비속어와 은어가 많은 것이 특징이 데이터셋
- 긍정 부정의 비율이 거의 1:1로 동일함

### 2-2. 데이터 전처리

---

#### **전처리** **방법**

---

- 한글과 공백을 제외한 모든 문자열 (숫자, 외국어, 마침표 등) 제거
- Konlpy의 Okt 형태소 분석기 사용
- 전체 데이터 셋에서 빈도가 1 인 단어는 과적합의 요인이 되므로 학습에서 제외 (빈도수 1인 단어가 전체 단어 수에서 차지하는 비율 54.7%)
- 불용어는 대게 한국어 조사로 이루어진 총 28개
- padding size: 55 (전체 데이터의 99.99% 보전)

#### **전처리** **결과**

---

- 총 sample 수: 495,137
- vocabulary: 89,789
- 학습 데이터 크기: 395,234
- 테스트 데이터 크기: 98,809
- 학습 데이터 테스트 데이터의 비율: 4:1
- 긍부정 라벨링 비율: 1:1

### 2-3. **사용한** **모델**

---

#### **BiLSTM**

---

- 모델 선정 이유:
  - RNN 기반 모델 3개(GRU, LSTM, BiLSTM)를 사용하여 모두 같은 조건에서 학습시켜 본 결과
    - GRU 모델의 정확도 83.33%
    - LSTM 모델의 정확도 86.55%
    - BiLSTM 모델의 정확도 86.27%
  - 테스트 데이터로 측정한 정확도의 경우 LSTM이 BiLSTM 보다 더 높았으나 자체 제작 챗봇 관련 데이터로 테스트를 진행했을 경우 BiLSTM이 챗봇과 관련한 리뷰의 뉘앙스를 더 잘 잡아내는 경향이 있어서 최종적으로 BiLSTM을 선정함
  - Bert 기반 모델 역시 학습시켰으나 방대한 양의 데이터와 학습을 시키는데 소모되는 시간이 RNN과 비교하여 4배 정도 더 길었으나 정확도에는 유의미한 차이가 없었기에 장기적으로 추가적인 학습을 시킨다는 가정 하에 시간적 기술적 자원을 더욱 효율적으로 사용할 수 있을 것이라 판단되는 RNN 모델을 최종적으로 선택함

#### **하이퍼파라미터 세팅**

---

- train validation ratio: 4:1
- embedding size: 100
- hidden units: 124
- **epoch: 15**
  - EarlyStopping() val_loss, min 설정
- activation function: sigmoid (binary classification이기 때문에)
- **optimizer: rmsprop**
  - optimizer로 adam을 사용해 보았으나 rmsprop이 성능이 아주 조금 더 좋았음
- **batch size: 64**
  - 방대한 양의 데이터
  - 한정된 메모리
  - 성능이 가장 잘 나온다는 mini batch로 32, 64의 옵션이 있었는데 하드웨어 스펙에 맞춰 64로 진행
